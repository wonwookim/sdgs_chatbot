import streamlit as st
import os
import sys
from pathlib import Path
from rag_chatbot import get_relevant_context, generate_response, extract_metadata_filters, expand_query
import chromadb
from chromadb.utils import embedding_functions
from dotenv import load_dotenv

# ... existing code ... 
# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# ChromaDB ì„¤ì •
embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(
        model_name="jhgan/ko-sroberta-multitask"
    )
    

client = chromadb.PersistentClient(path="./data/chromadb")
collection = client.get_collection(
    name="ppt_documents_collection",
    embedding_function=embedding_function
)

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ESG ì „ë¬¸ê°€ AI - ì±—ë´‡",
    page_icon="ğŸ’¬",
    layout="wide"
)

# ì œëª©
st.title("ğŸ’¬ ESG ì „ë¬¸ê°€ AI ì±—ë´‡")
st.markdown("RAG(Retrieval Augmented Generation) ê¸°ë°˜ ESG ì „ë¬¸ê°€ AIì™€ ëŒ€í™”í•´ë³´ì„¸ìš”.")

# ì‚¬ì´ë“œë°”ì— ëª¨ë¸ ID ì…ë ¥
with st.sidebar:
    st.header("ëª¨ë¸ ì„¤ì •")
    model_id = st.text_input(
        "íŒŒì¸íŠœë‹ëœ ëª¨ë¸ ID",
        help="íŒŒì¸íŠœë‹ì´ ì™„ë£Œëœ ëª¨ë¸ì˜ IDë¥¼ ì…ë ¥í•˜ì„¸ìš”"
    )
    
    if not model_id:
        st.warning("ëª¨ë¸ IDë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()

# ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
if "messages" not in st.session_state:
    st.session_state.messages = []

# ì´ì „ ëŒ€í™” ë‚´ìš© í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if "metadata_summary" in message:
            with st.expander("ì°¸ê³  ë¬¸ì„œ ì •ë³´"):
                st.json(message["metadata_summary"])

# ì‚¬ìš©ì ì…ë ¥
if prompt := st.chat_input("ESG ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # AI ì‘ë‹µ ìƒì„±
    with st.chat_message("assistant"):
        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
            try:
                # ì§ˆë¬¸ í™•ì¥
                expanded_query = expand_query(prompt)
                
                # ë©”íƒ€ë°ì´í„° í•„í„° ì¶”ì¶œ
                metadata_filters = extract_metadata_filters(expanded_query)
                
                # ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
                context, metadata_summary = get_relevant_context(
                    expanded_query,
                    collection,
                    metadata_filters=metadata_filters
                )
                
                # ì‘ë‹µ ìƒì„±
                response = generate_response(expanded_query, context, metadata_summary)
                
                st.markdown(response)
                
                # ë©”íƒ€ë°ì´í„° ìš”ì•½ ì •ë³´ í‘œì‹œ
                if metadata_summary:
                    with st.expander("ì°¸ê³  ë¬¸ì„œ ì •ë³´"):
                        st.json(metadata_summary)
                
                # ì‘ë‹µ ì €ì¥
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": response,
                    "metadata_summary": metadata_summary
                })
                
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

# ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
if st.sidebar.button("ëŒ€í™” ì´ˆê¸°í™”"):
    st.session_state.messages = []
    st.rerun() 